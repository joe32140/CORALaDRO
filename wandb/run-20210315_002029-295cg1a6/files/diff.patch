diff --git a/examples/algorithms/initializer.py b/examples/algorithms/initializer.py
index 00748cf..876bd7a 100644
--- a/examples/algorithms/initializer.py
+++ b/examples/algorithms/initializer.py
@@ -1,6 +1,8 @@
 from wilds.common.utils import get_counts
 from algorithms.ERM import ERM
 from algorithms.groupDRO import GroupDRO
+from algorithms.CORALaDRO import CORALaDRO
+from algorithms.KLaDRO import KLaDRO
 from algorithms.deepCORAL import DeepCORAL
 from algorithms.IRM import IRM
 from configs.supported import algo_log_metrics, losses
@@ -49,6 +51,31 @@ def initialize_algorithm(config, datasets, train_grouper):
             metric=metric,
             n_train_steps=n_train_steps,
             is_group_in_train=is_group_in_train)
+            
+    elif config.algorithm == 'CORALaDRO':
+        train_g = train_grouper.metadata_to_group(train_dataset.metadata_array)
+        is_group_in_train = get_counts(train_g, train_grouper.n_groups) > 0
+        algorithm = CORALaDRO(
+            config=config,
+            d_out=d_out,
+            grouper=train_grouper,
+            loss=loss,
+            metric=metric,
+            n_train_steps=n_train_steps,
+            is_group_in_train=is_group_in_train)
+    
+    elif config.algorithm == 'KLaDRO':
+        train_g = train_grouper.metadata_to_group(train_dataset.metadata_array)
+        is_group_in_train = get_counts(train_g, train_grouper.n_groups) > 0
+        algorithm = KLaDRO(
+            config=config,
+            d_out=d_out,
+            grouper=train_grouper,
+            loss=loss,
+            metric=metric,
+            n_train_steps=n_train_steps,
+            is_group_in_train=is_group_in_train)
+
     elif config.algorithm=='deepCORAL':
         algorithm = DeepCORAL(
             config=config,
diff --git a/examples/configs/algorithm.py b/examples/configs/algorithm.py
index 61787f0..959869c 100644
--- a/examples/configs/algorithm.py
+++ b/examples/configs/algorithm.py
@@ -11,6 +11,22 @@ algorithm_defaults = {
         'eval_loader': 'standard',
         'group_dro_step_size': 0.01,
     },
+    'CORALaDRO': {
+        'train_loader': 'group',
+        'uniform_over_groups': True,
+        'distinct_groups': True,
+        'eval_loader': 'standard',
+        'group_dro_step_size': 0.01,
+        'coral_penalty_weight': 1.,
+    },
+    'KLaDRO': {
+        'train_loader': 'group',
+        'uniform_over_groups': True,
+        'distinct_groups': True,
+        'eval_loader': 'standard',
+        'group_dro_step_size': 0.01,
+        'coral_penalty_weight': 1.,
+    },
     'deepCORAL': {
         'train_loader': 'group',
         'uniform_over_groups': True,
diff --git a/examples/configs/supported.py b/examples/configs/supported.py
index 8b66b74..fac5e0f 100644
--- a/examples/configs/supported.py
+++ b/examples/configs/supported.py
@@ -32,6 +32,6 @@ transforms = ['bert', 'image_base', 'image_resize_and_center_crop', 'poverty_tra
 models = ['resnet18_ms', 'resnet50', 'resnet34', 'wideresnet50',
          'densenet121', 'bert-base-uncased', 'distilbert-base-uncased',
          'gin-virtual', 'logistic_regression', 'code-gpt-py']
-algorithms = ['ERM', 'groupDRO', 'deepCORAL', 'IRM']
+algorithms = ['ERM', 'groupDRO', 'deepCORAL', 'IRM', 'CORALaDRO', 'KLaDRO']
 optimizers = ['SGD', 'Adam', 'AdamW']
 schedulers = ['linear_schedule_with_warmup', 'ReduceLROnPlateau', 'StepLR']
